import pandas as pd
import numpy as np
from typing import Dict, List, Any, Tuple
from datetime import datetime
import json

class DataQualityReporter:
    """æ•°æ®è´¨é‡æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.report_data = {}
    
    def analyze_excel_data(self, excel_data: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æExcelæ•°æ®è´¨é‡"""
        try:
            # è½¬æ¢æ•°æ®æ ¼å¼
            if isinstance(excel_data, list) and len(excel_data) > 0:
                if isinstance(excel_data[0], dict):
                    df = pd.DataFrame(excel_data)
                else:
                    df = pd.DataFrame(excel_data)
            else:
                df = pd.DataFrame(excel_data)
            
            # åŸºç¡€ç»Ÿè®¡
            basic_stats = self._get_basic_stats(df)
            
            # æ•°æ®è´¨é‡æŒ‡æ ‡
            quality_metrics = self._get_quality_metrics(df)
            
            # å­—æ®µåˆ†æ
            field_analysis = self._analyze_fields(df)
            
            # æ•°æ®å®Œæ•´æ€§
            completeness = self._analyze_completeness(df)
            
            # æ•°æ®ä¸€è‡´æ€§
            consistency = self._analyze_consistency(df)
            
            # ç”ŸæˆæŠ¥å‘Š
            report = {
                "timestamp": datetime.now().isoformat(),
                "basic_stats": basic_stats,
                "quality_metrics": quality_metrics,
                "field_analysis": field_analysis,
                "completeness": completeness,
                "consistency": consistency,
                "recommendations": self._generate_recommendations(quality_metrics, completeness, consistency)
            }
            
            self.report_data = report
            return report
            
        except Exception as e:
            return {"error": f"æ•°æ®åˆ†æå¤±è´¥: {str(e)}"}
    
    def _get_basic_stats(self, df: pd.DataFrame) -> Dict[str, Any]:
        """è·å–åŸºç¡€ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_rows": len(df),
            "total_columns": len(df.columns),
            "memory_usage": df.memory_usage(deep=True).sum(),
            "data_types": df.dtypes.to_dict()
        }
    
    def _get_quality_metrics(self, df: pd.DataFrame) -> Dict[str, Any]:
        """è·å–æ•°æ®è´¨é‡æŒ‡æ ‡"""
        metrics = {}
        
        for col in df.columns:
            col_data = df[col]
            
            # ç©ºå€¼ç»Ÿè®¡
            null_count = col_data.isnull().sum()
            null_percentage = (null_count / len(df)) * 100
            
            # å”¯ä¸€å€¼ç»Ÿè®¡
            unique_count = col_data.nunique()
            unique_percentage = (unique_count / len(df)) * 100
            
            # æ•°æ®ç±»å‹
            data_type = str(col_data.dtype)
            
            # æ•°å€¼å‹æ•°æ®çš„ç»Ÿè®¡
            if pd.api.types.is_numeric_dtype(col_data):
                try:
                    numeric_stats = {
                        "min": float(col_data.min()) if not pd.isna(col_data.min()) else None,
                        "max": float(col_data.max()) if not pd.isna(col_data.max()) else None,
                        "mean": float(col_data.mean()) if not pd.isna(col_data.mean()) else None,
                        "std": float(col_data.std()) if not pd.isna(col_data.std()) else None
                    }
                except:
                    numeric_stats = None
            else:
                numeric_stats = None
            
            metrics[col] = {
                "null_count": int(null_count),
                "null_percentage": round(null_percentage, 2),
                "unique_count": int(unique_count),
                "unique_percentage": round(unique_percentage, 2),
                "data_type": data_type,
                "numeric_stats": numeric_stats
            }
        
        return metrics
    
    def _analyze_fields(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æå­—æ®µç‰¹å¾"""
        field_analysis = {}
        
        for col in df.columns:
            col_data = df[col]
            
            # å­—æ®µåç§°åˆ†æ
            field_name = str(col)
            field_name_lower = field_name.lower()
            
            # å­—æ®µç±»å‹æ¨æ–­
            field_type = self._infer_field_type(field_name_lower, col_data)
            
            # å­—æ®µé‡è¦æ€§è¯„åˆ†
            importance_score = self._calculate_importance_score(field_name_lower, col_data)
            
            field_analysis[col] = {
                "inferred_type": field_type,
                "importance_score": importance_score,
                "keywords": self._extract_keywords(field_name_lower)
            }
        
        return field_analysis
    
    def _infer_field_type(self, field_name: str, col_data: pd.Series) -> str:
        """æ¨æ–­å­—æ®µç±»å‹"""
        # åŸºäºå­—æ®µåçš„æ¨æ–­
        if any(keyword in field_name for keyword in ["æ—¥æœŸ", "æ—¶é—´", "date", "time"]):
            return "date"
        elif any(keyword in field_name for keyword in ["ç¼–å·", "ç¼–ç ", "code", "id", "å·"]):
            return "identifier"
        elif any(keyword in field_name for keyword in ["æ•°é‡", "ä»¶æ•°", "ä½“ç§¯", "é‡é‡", "count", "volume", "weight"]):
            return "quantity"
        elif any(keyword in field_name for keyword in ["åç§°", "name", "åœ°å€", "address", "å…¬å¸", "company"]):
            return "name"
        elif any(keyword in field_name for keyword in ["ä»·æ ¼", "é‡‘é¢", "price", "amount", "cost"]):
            return "price"
        else:
            return "unknown"
    
    def _calculate_importance_score(self, field_name: str, col_data: pd.Series) -> float:
        """è®¡ç®—å­—æ®µé‡è¦æ€§è¯„åˆ†"""
        score = 0.0
        
        # åŸºäºå­—æ®µåçš„è¯„åˆ†
        if any(keyword in field_name for keyword in ["è®¢å•", "è¿å•", "order", "waybill"]):
            score += 0.3
        if any(keyword in field_name for keyword in ["æ—¥æœŸ", "æ—¶é—´", "date", "time"]):
            score += 0.2
        if any(keyword in field_name for keyword in ["æ•°é‡", "ä»¶æ•°", "count", "qty"]):
            score += 0.2
        if any(keyword in field_name for keyword in ["åç§°", "name"]):
            score += 0.1
        
        # åŸºäºæ•°æ®ç‰¹å¾çš„è¯„åˆ†
        null_percentage = col_data.isnull().sum() / len(col_data)
        if null_percentage < 0.1:  # ç©ºå€¼ç‡ä½
            score += 0.1
        if null_percentage < 0.5:  # ç©ºå€¼ç‡ä¸­ç­‰
            score += 0.05
        
        unique_percentage = col_data.nunique() / len(col_data)
        if 0.1 < unique_percentage < 0.9:  # å”¯ä¸€æ€§é€‚ä¸­
            score += 0.1
        
        return min(score, 1.0)
    
    def _extract_keywords(self, field_name: str) -> List[str]:
        """æå–å­—æ®µå…³é”®è¯"""
        keywords = []
        
        # ä¸­æ–‡å…³é”®è¯
        chinese_keywords = ["è®¢å•", "è¿å•", "æ—¥æœŸ", "æ—¶é—´", "æ•°é‡", "ä»¶æ•°", "ä½“ç§¯", "é‡é‡", 
                           "åç§°", "ç¼–å·", "ç¼–ç ", "åœ°å€", "å…¬å¸", "ä»·æ ¼", "é‡‘é¢"]
        
        # è‹±æ–‡å…³é”®è¯
        english_keywords = ["order", "waybill", "date", "time", "count", "qty", "volume", 
                           "weight", "name", "id", "code", "address", "company", "price", "amount"]
        
        for keyword in chinese_keywords + english_keywords:
            if keyword in field_name:
                keywords.append(keyword)
        
        return keywords
    
    def _analyze_completeness(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†ææ•°æ®å®Œæ•´æ€§"""
        completeness = {}
        
        # æ•´ä½“å®Œæ•´æ€§
        total_cells = len(df) * len(df.columns)
        null_cells = df.isnull().sum().sum()
        overall_completeness = ((total_cells - null_cells) / total_cells) * 100
        
        completeness["overall"] = round(overall_completeness, 2)
        
        # è¡Œå®Œæ•´æ€§
        row_completeness = []
        for idx, row in df.iterrows():
            null_count = row.isnull().sum()
            row_comp = ((len(row) - null_count) / len(row)) * 100
            row_completeness.append(round(row_comp, 2))
        
        completeness["row_stats"] = {
            "min": min(row_completeness),
            "max": max(row_completeness),
            "mean": round(np.mean(row_completeness), 2),
            "std": round(np.std(row_completeness), 2)
        }
        
        # åˆ—å®Œæ•´æ€§
        col_completeness = {}
        for col in df.columns:
            null_count = df[col].isnull().sum()
            col_comp = ((len(df) - null_count) / len(df)) * 100
            col_completeness[col] = round(col_comp, 2)
        
        completeness["column_stats"] = col_completeness
        
        return completeness
    
    def _analyze_consistency(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†ææ•°æ®ä¸€è‡´æ€§"""
        consistency = {}
        
        for col in df.columns:
            col_data = df[col]
            
            # æ•°æ®ç±»å‹ä¸€è‡´æ€§
            type_consistency = 1.0
            if len(col_data) > 0:
                expected_type = type(col_data.iloc[0])
                type_matches = sum(1 for val in col_data if type(val) == expected_type)
                type_consistency = type_matches / len(col_data)
            
            # æ ¼å¼ä¸€è‡´æ€§ï¼ˆå¯¹äºå­—ç¬¦ä¸²ç±»å‹ï¼‰
            format_consistency = 1.0
            if col_data.dtype == 'object':
                # æ£€æŸ¥å­—ç¬¦ä¸²é•¿åº¦çš„ä¸€è‡´æ€§
                str_lengths = [len(str(val)) for val in col_data if pd.notna(val)]
                if str_lengths:
                    avg_length = np.mean(str_lengths)
                    length_variance = np.var(str_lengths)
                    format_consistency = 1 / (1 + length_variance / (avg_length + 1))
            
            consistency[col] = {
                "type_consistency": round(type_consistency, 3),
                "format_consistency": round(format_consistency, 3),
                "overall_consistency": round((type_consistency + format_consistency) / 2, 3)
            }
        
        return consistency
    
    def _generate_recommendations(self, quality_metrics: Dict, completeness: Dict, consistency: Dict) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        # åŸºäºè´¨é‡æŒ‡æ ‡çš„å»ºè®®
        for field, metrics in quality_metrics.items():
            if metrics["null_percentage"] > 50:
                recommendations.append(f"å­—æ®µ '{field}' ç©ºå€¼ç‡è¿‡é«˜ ({metrics['null_percentage']}%)ï¼Œå»ºè®®æ£€æŸ¥æ•°æ®æºæˆ–è€ƒè™‘åˆ é™¤")
            
            if metrics["unique_percentage"] < 5:
                recommendations.append(f"å­—æ®µ '{field}' å”¯ä¸€æ€§è¿‡ä½ ({metrics['unique_percentage']}%)ï¼Œå¯èƒ½åŒ…å«é‡å¤æˆ–æ— æ•ˆæ•°æ®")
        
        # åŸºäºå®Œæ•´æ€§çš„å»ºè®®
        if completeness["overall"] < 80:
            recommendations.append(f"æ•´ä½“æ•°æ®å®Œæ•´æ€§è¾ƒä½ ({completeness['overall']}%)ï¼Œå»ºè®®æ£€æŸ¥æ•°æ®é‡‡é›†æµç¨‹")
        
        # åŸºäºä¸€è‡´æ€§çš„å»ºè®®
        for field, cons in consistency.items():
            if cons["overall_consistency"] < 0.7:
                recommendations.append(f"å­—æ®µ '{field}' ä¸€è‡´æ€§è¾ƒä½ ({cons['overall_consistency']})ï¼Œå»ºè®®ç»Ÿä¸€æ•°æ®æ ¼å¼")
        
        if not recommendations:
            recommendations.append("æ•°æ®è´¨é‡è‰¯å¥½ï¼Œæ— éœ€ç‰¹åˆ«æ”¹è¿›")
        
        return recommendations
    
    def generate_html_report(self) -> str:
        """ç”ŸæˆHTMLæ ¼å¼çš„æŠ¥å‘Š"""
        if not self.report_data:
            return "<h1>æ²¡æœ‰å¯ç”¨çš„æŠ¥å‘Šæ•°æ®</h1>"
        
        html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="utf-8">
            <title>æ•°æ®è´¨é‡æŠ¥å‘Š</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                .header {{ background: #f0f0f0; padding: 20px; border-radius: 5px; }}
                .section {{ margin: 20px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }}
                .metric {{ display: inline-block; margin: 10px; padding: 10px; background: #f9f9f9; border-radius: 3px; }}
                .warning {{ color: #ff6600; }}
                .error {{ color: #cc0000; }}
                .success {{ color: #009900; }}
                table {{ border-collapse: collapse; width: 100%; }}
                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                th {{ background-color: #f2f2f2; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>ğŸ“Š æ•°æ®è´¨é‡æŠ¥å‘Š</h1>
                <p>ç”Ÿæˆæ—¶é—´: {self.report_data.get('timestamp', 'N/A')}</p>
            </div>
            
            <div class="section">
                <h2>ğŸ“ˆ åŸºç¡€ç»Ÿè®¡</h2>
                <div class="metric">æ€»è¡Œæ•°: {self.report_data.get('basic_stats', {}).get('total_rows', 'N/A')}</div>
                <div class="metric">æ€»åˆ—æ•°: {self.report_data.get('basic_stats', {}).get('total_columns', 'N/A')}</div>
                <div class="metric">å†…å­˜ä½¿ç”¨: {self.report_data.get('basic_stats', {}).get('memory_usage', 'N/A')} bytes</div>
            </div>
            
            <div class="section">
                <h2>ğŸ” æ•°æ®è´¨é‡æŒ‡æ ‡</h2>
                <table>
                    <tr>
                        <th>å­—æ®µå</th>
                        <th>ç©ºå€¼ç‡</th>
                        <th>å”¯ä¸€æ€§</th>
                        <th>æ•°æ®ç±»å‹</th>
                    </tr>
        """
        
        for field, metrics in self.report_data.get('quality_metrics', {}).items():
            null_class = "warning" if metrics['null_percentage'] > 30 else "success"
            unique_class = "warning" if metrics['unique_percentage'] < 10 else "success"
            
            html += f"""
                    <tr>
                        <td>{field}</td>
                        <td class="{null_class}">{metrics['null_percentage']}%</td>
                        <td class="{unique_class}">{metrics['unique_percentage']}%</td>
                        <td>{metrics['data_type']}</td>
                    </tr>
            """
        
        html += """
                </table>
            </div>
            
            <div class="section">
                <h2>ğŸ“‹ æ”¹è¿›å»ºè®®</h2>
                <ul>
        """
        
        for rec in self.report_data.get('recommendations', []):
            html += f"<li>{rec}</li>"
        
        html += """
                </ul>
            </div>
        </body>
        </html>
        """
        
        return html
    
    def save_report(self, filename: str = None) -> str:
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"data_quality_report_{timestamp}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.report_data, f, ensure_ascii=False, indent=2)
            return filename
        except Exception as e:
            raise Exception(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {str(e)}")


# å…¨å±€å®ä¾‹
data_quality_reporter = DataQualityReporter() 